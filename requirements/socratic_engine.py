"""
SOCRATIC QUESTION ENGINE (Phase 2: Dialectic Specification)

This engine powers the second phase of the two-phase specification process:
  Phase 1 (Intake Wizard): Deterministic data collection â†’ prompt.md
  Phase 2 (This): AI-driven gap analysis and clarification

The Socrates agent:
1. Reads prompt.md generated by Phase 1
2. Identifies gaps, ambiguities, and incomplete specifications
3. Asks L2 (module-level) questions per feature
4. Asks L3 (node-level) questions only for structural validators
5. Converses with user via chat to resolve clarifications
6. Generates SPEC nodes when specifications are sufficiently clear

Key Design Principles:
- L1 questions cost O(1) - asked once in Phase 1
- L2 questions cost O(n) - asked per module/feature
- L3 questions cost O(m) - asked only when structural validators fail
- Never invent data - ask user or mark as CLARIFICATION
- Terminal question: "is there anything else?" grants delegation license
"""

import os
import re
import json
import uuid
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from core.ontology import NodeType, EdgeType, NodeStatus


logger = logging.getLogger("GAADP.SocraticEngine")


# =============================================================================
# CANONICAL QUESTIONS (from docs/canonical_questions_final.tsv)
# =============================================================================

class QuestionLevel(Enum):
    """Question hierarchy level."""
    L1_SYSTEM = "L1"      # System-wide, asked once in Phase 1
    L2_MODULE = "L2"      # Per-module, asked for each feature
    L3_NODE = "L3"        # Per-node, conditional on structural validation
    TERMINAL = "TERMINAL" # Wrap-up questions


class AskCondition(Enum):
    """When to ask a question."""
    ALWAYS = "Always"
    IF_AMBIGUOUS = "If_Ambiguous"
    IF_NO_GRAPH_STRUCTURE = "If_No_Graph_Structure"
    STRUCTURAL_VALIDATOR = "Structural_Validator"


@dataclass
class CanonicalQuestion:
    """A canonical question from the curated list."""
    id: str
    level: QuestionLevel
    ask_when: AskCondition
    category: str
    question: str
    technical_name: str
    notes: str


# L2 Module-Level Questions (asked per feature)
L2_QUESTIONS = [
    CanonicalQuestion(
        id="L2.01",
        level=QuestionLevel.L2_MODULE,
        ask_when=AskCondition.ALWAYS,
        category="Boundary",
        question="What kicks off this feature, and what means it's finished?",
        technical_name="Trigger and Exit Condition",
        notes="Defines module boundaries"
    ),
    CanonicalQuestion(
        id="L2.02",
        level=QuestionLevel.L2_MODULE,
        ask_when=AskCondition.ALWAYS,
        category="Data Flow",
        question="Does this handle one thing at a time, batches, or a continuous stream? Does the user wait for results or can it run in background?",
        technical_name="Cardinality and Latency",
        notes="Architectural decision: sync vs async, single vs batch"
    ),
    CanonicalQuestion(
        id="L2.03",
        level=QuestionLevel.L2_MODULE,
        ask_when=AskCondition.ALWAYS,
        category="Topology",
        question="What does this feature need from other parts, and what does it provide to them?",
        technical_name="Dependencies and Dependents",
        notes="Critical for graph structure"
    ),
    CanonicalQuestion(
        id="L2.04",
        level=QuestionLevel.L2_MODULE,
        ask_when=AskCondition.ALWAYS,
        category="Data Ownership",
        question="Does this feature own its data, or borrow it from somewhere else?",
        technical_name="Data Sovereignty",
        notes="Determines source of truth"
    ),
    CanonicalQuestion(
        id="L2.05",
        level=QuestionLevel.L2_MODULE,
        ask_when=AskCondition.IF_AMBIGUOUS,
        category="Fault Handling",
        question="If this feature breaks, should the whole app stop, or just this part?",
        technical_name="Fault Isolation",
        notes="Usually inferable from module criticality"
    ),
]

# L3 Node-Level Questions (conditional)
L3_QUESTIONS = [
    CanonicalQuestion(
        id="L3.01",
        level=QuestionLevel.L3_NODE,
        ask_when=AskCondition.IF_NO_GRAPH_STRUCTURE,
        category="Interface",
        question="What data goes in and what comes out? What format and rules?",
        technical_name="I/O Schema",
        notes="Only ask if not derivable from function signature or parent SPEC"
    ),
    CanonicalQuestion(
        id="L3.02",
        level=QuestionLevel.L3_NODE,
        ask_when=AskCondition.IF_AMBIGUOUS,
        category="Side Effects",
        question="Does this change anything permanent or external? (Database, email, payment, file)",
        technical_name="Side Effects and Idempotency",
        notes="Usually obvious from function name"
    ),
    CanonicalQuestion(
        id="L3.03",
        level=QuestionLevel.L3_NODE,
        ask_when=AskCondition.STRUCTURAL_VALIDATOR,
        category="Data Source",
        question="Where exactly does each input come from?",
        technical_name="Input Provenance",
        notes="NEVER guess - graph must have explicit edge or ask user"
    ),
    CanonicalQuestion(
        id="L3.04",
        level=QuestionLevel.L3_NODE,
        ask_when=AskCondition.STRUCTURAL_VALIDATOR,
        category="Hidden State",
        question="Does this need any information not passed in directly?",
        technical_name="Implicit Dependencies",
        notes="NEVER guess - catches 'magic variables'"
    ),
]

# Terminal Questions
TERMINAL_QUESTIONS = [
    CanonicalQuestion(
        id="T1",
        level=QuestionLevel.TERMINAL,
        ask_when=AskCondition.ALWAYS,
        category="Assumptions",
        question="Here's what I'm assuming: [LIST]. Correct? Anything else?",
        technical_name="Assumptions Review",
        notes="Surfaces inferences for correction before proceeding"
    ),
    CanonicalQuestion(
        id="T2",
        level=QuestionLevel.TERMINAL,
        ask_when=AskCondition.ALWAYS,
        category="Delegation",
        question="Want to skip any of these questions? I'll use my best judgment for skipped items.",
        technical_name="Delegation License",
        notes="User can say 'skip' to delegate decision to agent"
    ),
]


# =============================================================================
# PROMPT.MD PARSER
# =============================================================================

@dataclass
class ParsedPrompt:
    """Structured representation of prompt.md."""
    problem_statement: str
    user_persona: str
    integrations: str
    compliance: List[str]
    timeline: str
    budget: str
    scale_current: str
    scale_projected: str
    platforms: List[str]
    speed_vs_robustness: str
    features: List[str]
    additional_requirements: str
    delegations: List[str]
    raw_content: str


class PromptParser:
    """Parse prompt.md files generated by intake wizard."""

    @staticmethod
    def parse(content: str) -> ParsedPrompt:
        """Parse prompt.md content into structured form."""

        def extract_section(pattern: str, default: str = "") -> str:
            """Extract content from a markdown section."""
            match = re.search(pattern, content, re.DOTALL)
            return match.group(1).strip() if match else default

        def extract_code_block(section_id: str) -> str:
            """Extract content from a code block after a section ID."""
            pattern = rf'\*\*{section_id}\*\*\s*```\s*(.*?)\s*```'
            match = re.search(pattern, content, re.DOTALL)
            return match.group(1).strip() if match else ""

        def extract_list_items(pattern: str) -> List[str]:
            """Extract list items from a section."""
            section = extract_section(pattern)
            items = re.findall(r'[-*]\s*\[.\]\s*(.*?)(?:\n|$)', section)
            return [item.strip() for item in items if item.strip()]

        # Extract L1 answers
        problem = extract_code_block("L1.01")
        persona = extract_code_block("L1.02")
        integrations = extract_code_block("L1.03")
        compliance_text = extract_code_block("L1.04")
        timeline = extract_code_block("L1.05")
        budget = extract_code_block("L1.06")
        scale = extract_code_block("L1.07")
        platform_text = extract_code_block("L1.08")
        tradeoff = extract_code_block("L1.09")

        # Parse scale
        scale_parts = scale.split(",") if "," in scale else [scale, ""]
        scale_current = scale_parts[0].strip() if scale_parts else ""
        scale_projected = scale_parts[1].strip() if len(scale_parts) > 1 else ""

        # Parse compliance list
        compliance = []
        for item in ["HIPAA", "GDPR", "PCI-DSS", "SOC2"]:
            if item.lower() in compliance_text.lower():
                compliance.append(item)

        # Parse platforms
        platforms = [p.strip() for p in platform_text.split(",") if p.strip()]

        # Extract features
        features = []
        features_section = re.search(
            r'## Feature List.*?### Core Features\s*(.*?)(?:###|---|\Z)',
            content, re.DOTALL
        )
        if features_section:
            feature_lines = features_section.group(1).strip().split('\n')
            for line in feature_lines:
                match = re.match(r'[-*]\s*\[.\]\s*(.*)', line)
                if match:
                    features.append(match.group(1).strip())

        # Extract additional requirements
        additional_match = re.search(
            r'### Additional Requirements\s*```\s*(.*?)\s*```',
            content, re.DOTALL
        )
        additional = additional_match.group(1).strip() if additional_match else ""

        # Extract delegations
        delegations = []
        delegation_section = re.search(
            r'## Delegation License.*?(?:---|\Z)',
            content, re.DOTALL
        )
        if delegation_section:
            delegation_lines = delegation_section.group(0).split('\n')
            for line in delegation_lines:
                match = re.match(r'[-*]\s*\*\*(.*?)\*\*:\s*(.*)$', line)
                if match and "Agent may decide" in match.group(2):
                    delegations.append(match.group(1))

        return ParsedPrompt(
            problem_statement=problem,
            user_persona=persona,
            integrations=integrations,
            compliance=compliance,
            timeline=timeline,
            budget=budget,
            scale_current=scale_current,
            scale_projected=scale_projected,
            platforms=platforms,
            speed_vs_robustness=tradeoff,
            features=features,
            additional_requirements=additional,
            delegations=delegations,
            raw_content=content
        )


# =============================================================================
# GAP ANALYZER
# =============================================================================

@dataclass
class Gap:
    """An identified gap in the specification."""
    feature: str
    question_id: str
    question: str
    category: str
    reason: str
    blocking: bool = True


class GapAnalyzer:
    """Analyze prompt.md for gaps and missing information."""

    def __init__(self, parsed: ParsedPrompt):
        self.parsed = parsed
        self.gaps: List[Gap] = []

    def analyze(self) -> List[Gap]:
        """Run all gap analysis checks."""
        self.gaps = []

        # Analyze each feature for L2 questions
        for feature in self.parsed.features:
            self._analyze_feature(feature)

        # Check for missing L1 information
        self._check_l1_completeness()

        return self.gaps

    def _analyze_feature(self, feature: str):
        """Analyze a single feature for L2 gaps."""

        # L2.01: Trigger and Exit - always ask
        self.gaps.append(Gap(
            feature=feature,
            question_id="L2.01",
            question=f"For '{feature}': What kicks off this feature, and what means it's finished?",
            category="Boundary",
            reason="Module boundary not specified",
            blocking=True
        ))

        # L2.02: Cardinality and Latency - always ask
        self.gaps.append(Gap(
            feature=feature,
            question_id="L2.02",
            question=f"For '{feature}': Does this handle one thing at a time, batches, or a continuous stream? Does the user wait for results?",
            category="Data Flow",
            reason="Processing model not specified",
            blocking=True
        ))

        # L2.03: Dependencies - always ask
        self.gaps.append(Gap(
            feature=feature,
            question_id="L2.03",
            question=f"For '{feature}': What does this feature need from other parts, and what does it provide to them?",
            category="Topology",
            reason="Dependencies not specified",
            blocking=True
        ))

        # L2.04: Data Ownership - always ask
        self.gaps.append(Gap(
            feature=feature,
            question_id="L2.04",
            question=f"For '{feature}': Does this feature own its data, or borrow it from somewhere else?",
            category="Data Ownership",
            reason="Data sovereignty not specified",
            blocking=True
        ))

    def _check_l1_completeness(self):
        """Check if L1 information is complete."""
        p = self.parsed

        if not p.problem_statement or p.problem_statement == "Not specified":
            self.gaps.append(Gap(
                feature="SYSTEM",
                question_id="L1.01",
                question="What is the single most important problem this software solves?",
                category="Problem",
                reason="Problem statement missing",
                blocking=True
            ))

        if not p.user_persona or p.user_persona == "Not specified":
            self.gaps.append(Gap(
                feature="SYSTEM",
                question_id="L1.02",
                question="Who exactly will use this? Describe the person at the keyboard.",
                category="Users",
                reason="User persona missing",
                blocking=True
            ))


# =============================================================================
# SOCRATIC ENGINE (Main Class)
# =============================================================================

class SocraticEngine:
    """
    Phase 2: Dialectic Specification Engine

    Takes prompt.md from Phase 1 and conducts a Socratic dialogue
    to fill gaps and generate complete specifications.
    """

    def __init__(self, prompt_path: Optional[str] = None):
        """
        Initialize the Socratic Engine.

        Args:
            prompt_path: Path to prompt.md file (optional, can load later)
        """
        self.prompt_path = prompt_path
        self.parsed: Optional[ParsedPrompt] = None
        self.gaps: List[Gap] = []
        self.answers: Dict[str, str] = {}
        self.assumptions: Dict[str, str] = {}
        self.conversation_history: List[Dict[str, str]] = []

    def load_prompt(self, path: Optional[str] = None) -> ParsedPrompt:
        """Load and parse a prompt.md file."""
        path = path or self.prompt_path
        if not path:
            raise ValueError("No prompt path specified")

        if not Path(path).exists():
            raise FileNotFoundError(f"Prompt file not found: {path}")

        content = Path(path).read_text()
        self.parsed = PromptParser.parse(content)
        return self.parsed

    def analyze_gaps(self) -> List[Gap]:
        """Analyze the loaded prompt for gaps."""
        if not self.parsed:
            raise ValueError("No prompt loaded. Call load_prompt() first.")

        analyzer = GapAnalyzer(self.parsed)
        self.gaps = analyzer.analyze()
        return self.gaps

    def get_next_question(self) -> Optional[Gap]:
        """Get the next unanswered gap/question."""
        for gap in self.gaps:
            key = f"{gap.feature}:{gap.question_id}"
            if key not in self.answers:
                return gap
        return None

    def answer_question(self, gap: Gap, answer: str) -> Dict[str, Any]:
        """
        Record an answer to a question.

        Args:
            gap: The gap being answered
            answer: User's answer

        Returns:
            Result dict with any follow-up actions
        """
        key = f"{gap.feature}:{gap.question_id}"
        self.answers[key] = answer

        # Record in conversation history
        self.conversation_history.append({
            "role": "assistant",
            "content": gap.question
        })
        self.conversation_history.append({
            "role": "user",
            "content": answer
        })

        # Check if answer triggers L3 questions
        if gap.question_id.startswith("L2"):
            l3_gaps = self._check_l3_triggers(gap, answer)
            self.gaps.extend(l3_gaps)

        return {
            "answered": key,
            "remaining": len([g for g in self.gaps if f"{g.feature}:{g.question_id}" not in self.answers]),
            "new_questions": len([g for g in self.gaps if f"{g.feature}:{g.question_id}" not in self.answers])
        }

    def _check_l3_triggers(self, gap: Gap, answer: str) -> List[Gap]:
        """Check if L2 answer triggers L3 questions."""
        new_gaps = []

        # L3.03: Data Source - structural validator, always check
        # If answer mentions "input from" but doesn't specify source
        if "input" in answer.lower() and "from" not in answer.lower():
            new_gaps.append(Gap(
                feature=gap.feature,
                question_id="L3.03",
                question=f"For '{gap.feature}': Where exactly does each input come from?",
                category="Data Source",
                reason="Input provenance unclear",
                blocking=True
            ))

        # L3.04: Hidden State - structural validator
        # If answer mentions "uses" or "needs" something not explicitly passed
        if any(word in answer.lower() for word in ["uses", "needs", "requires", "depends"]):
            new_gaps.append(Gap(
                feature=gap.feature,
                question_id="L3.04",
                question=f"For '{gap.feature}': Does this need any information not passed in directly?",
                category="Hidden State",
                reason="Potential implicit dependencies detected",
                blocking=True
            ))

        return new_gaps

    def generate_spec_node(self, feature: str) -> Dict[str, Any]:
        """
        Generate a SPEC node for a feature once all gaps are answered.

        Args:
            feature: The feature name

        Returns:
            Node data for the graph
        """
        # Collect all answers for this feature
        feature_answers = {
            k.split(":")[1]: v
            for k, v in self.answers.items()
            if k.startswith(f"{feature}:")
        }

        # Build specification content
        spec_content = {
            "feature": feature,
            "trigger": feature_answers.get("L2.01", "Not specified"),
            "data_flow": feature_answers.get("L2.02", "Not specified"),
            "dependencies": feature_answers.get("L2.03", "Not specified"),
            "data_ownership": feature_answers.get("L2.04", "Not specified"),
            "fault_handling": feature_answers.get("L2.05", "Agent decides"),
            "l3_details": {
                k: v for k, v in feature_answers.items()
                if k.startswith("L3")
            }
        }

        spec_id = f"spec_{uuid.uuid4().hex[:8]}"

        return {
            "id": spec_id,
            "type": NodeType.SPEC.value,
            "status": NodeStatus.PENDING.value,
            "content": json.dumps(spec_content, indent=2),
            "metadata": {
                "feature": feature,
                "source": "socratic_engine",
                "questions_answered": len(feature_answers)
            }
        }

    def generate_clarification_node(self, gap: Gap, parent_req_id: str) -> Dict[str, Any]:
        """
        Create a CLARIFICATION node for a blocking question.

        Args:
            gap: The gap requiring clarification
            parent_req_id: ID of the parent requirement node

        Returns:
            Dict with node and edge data
        """
        question_id = f"clarification_{uuid.uuid4().hex[:8]}"

        node_data = {
            "id": question_id,
            "type": NodeType.CLARIFICATION.value,
            "status": NodeStatus.PENDING.value,
            "content": gap.question,
            "metadata": {
                "source_type": "USER",
                "source_agent": "SOCRATES",
                "question_id": gap.question_id,
                "category": gap.category,
                "feature": gap.feature,
                "blocking": gap.blocking,
                "impact_level": "blocking" if gap.blocking else "clarifying",
                "ambiguity_type": self._infer_ambiguity_type(gap.category),
            }
        }

        edge_data = {
            "source": question_id,
            "target": parent_req_id,
            "type": EdgeType.BLOCKS.value if gap.blocking else EdgeType.TRACES_TO.value
        }

        return {"node": node_data, "edge": edge_data}

    def get_assumptions_summary(self) -> str:
        """Generate a summary of assumptions for terminal question T1."""
        if not self.parsed:
            return "No prompt loaded"

        assumptions = []

        # Inferred from L1
        if self.parsed.speed_vs_robustness:
            assumptions.append(f"Build approach: {self.parsed.speed_vs_robustness}")

        if self.parsed.platforms:
            assumptions.append(f"Target platforms: {', '.join(self.parsed.platforms)}")

        if self.parsed.compliance:
            assumptions.append(f"Compliance requirements: {', '.join(self.parsed.compliance)}")
        else:
            assumptions.append("No special compliance requirements")

        # Add delegations
        if self.parsed.delegations:
            assumptions.append(f"Agent can decide: {', '.join(self.parsed.delegations)}")

        return "\n".join(f"- {a}" for a in assumptions)

    def _infer_ambiguity_type(self, category: str) -> str:
        """
        Map gap category to ambiguity type for DIALECTOR compatibility.

        Ambiguity types (from DIALECTOR prompt):
        - subjective: Quality/UX terms without measurable definitions
        - comparative: Comparisons without baselines
        - pronoun: Undefined references
        - undefined_term: Domain-specific terms needing definition
        - missing_context: Information gaps preventing implementation
        """
        category_to_ambiguity = {
            "Boundary": "missing_context",
            "Data Flow": "missing_context",
            "Topology": "missing_context",
            "Data Ownership": "missing_context",
            "Fault Handling": "missing_context",
            "Interface": "missing_context",
            "Side Effects": "missing_context",
            "Data Source": "missing_context",
            "Hidden State": "missing_context",
            "Problem": "missing_context",
            "Users": "missing_context",
        }
        return category_to_ambiguity.get(category, "missing_context")

    def get_status(self) -> Dict[str, Any]:
        """Get current status of the dialectic process."""
        total_gaps = len(self.gaps)
        answered = len(self.answers)
        remaining = total_gaps - answered

        return {
            "total_questions": total_gaps,
            "answered": answered,
            "remaining": remaining,
            "features_analyzed": len(self.parsed.features) if self.parsed else 0,
            "completion_percentage": (answered / total_gaps * 100) if total_gaps > 0 else 0,
            "ready_for_spec_generation": remaining == 0
        }

    # =========================================================================
    # LEGACY API (backward compatibility)
    # =========================================================================

    def analyze_gap(self, gap_description: str, parent_req_id: str) -> Dict[str, Any]:
        """
        Legacy method for creating clarification nodes.

        Kept for backward compatibility with existing code.
        """
        question_id = f"req_{uuid.uuid4().hex[:8]}"
        source = "USER"

        if any(x in gap_description.lower() for x in ["api", "format", "syntax"]):
            source = "SEARCH"

        node_data = {
            "id": question_id,
            "type": NodeType.REQ.value,
            "status": NodeStatus.PENDING.value,
            "content": gap_description,
            "metadata": {
                "source_type": source,
                "ambiguity_score": 1.0,
                "parent_id": parent_req_id
            }
        }

        edge_data = {
            "source": question_id,
            "target": parent_req_id,
            "type": EdgeType.TRACES_TO.value
        }

        return {"node": node_data, "edge": edge_data}


# =============================================================================
# VIZSERVER INTEGRATION (Mission Control Chat Panel)
# =============================================================================

class SocraticVizSession:
    """
    Integrates Socratic Q&A with the existing VizServer chat infrastructure.

    Uses VizServer.ask_user() and send_chat_message() to communicate
    with users through the Mission Control dashboard on ports 8765/8766.

    Usage:
        from infrastructure.viz_server import get_viz_server
        from requirements.socratic_engine import SocraticEngine, SocraticVizSession

        viz = get_viz_server()
        engine = SocraticEngine()
        session = SocraticVizSession(engine, viz)
        await session.run_session("prompts/prompt.md")
    """

    def __init__(self, engine: SocraticEngine, viz_server):
        """
        Initialize the VizServer-integrated Socratic session.

        Args:
            engine: SocraticEngine instance
            viz_server: VizServer instance from infrastructure.viz_server
        """
        self.engine = engine
        self.viz = viz_server
        self.current_gap: Optional[Gap] = None

    async def run_session(self, prompt_path: str) -> bool:
        """
        Run a complete Socratic Q&A session via VizServer chat.

        Args:
            prompt_path: Path to prompt.md file

        Returns:
            True if session completed successfully, False if cancelled/timeout
        """
        # Load and analyze prompt
        self.engine.load_prompt(prompt_path)
        self.engine.analyze_gaps()

        status = self.engine.get_status()

        # Send intro message
        await self.viz.send_chat_message(
            f"ðŸ“‹ Socratic Specification Session\n\n"
            f"I've analyzed your requirements and have {status['total_questions']} questions "
            f"to ensure we build exactly what you need.\n\n"
            f"Features identified: {status['features_analyzed']}\n"
            f"Questions to answer: {status['remaining']}\n\n"
            f"You can say 'skip' at any time to let me use my best judgment.",
            agent_role="SOCRATES"
        )

        # Ask each question
        while True:
            self.current_gap = self.engine.get_next_question()

            if not self.current_gap:
                # All questions answered
                break

            # Format the question
            category_emoji = {
                "Boundary": "ðŸŽ¯",
                "Data Flow": "ðŸ”„",
                "Topology": "ðŸ”—",
                "Data Ownership": "ðŸ“Š",
                "Fault Handling": "âš ï¸",
                "Data Source": "ðŸ“¥",
                "Hidden State": "ðŸ”",
            }.get(self.current_gap.category, "â“")

            question_text = (
                f"{category_emoji} {self.current_gap.category} ({self.current_gap.question_id})\n\n"
                f"{self.current_gap.question}\n\n"
                f"Feature: {self.current_gap.feature}"
            )

            # Ask via VizServer (waits for user response)
            response = await self.viz.ask_user(
                question=question_text,
                context={
                    "agent_role": "SOCRATES",
                    "question_id": self.current_gap.question_id,
                    "feature": self.current_gap.feature,
                    "category": self.current_gap.category
                },
                options=["skip"] if self.current_gap.category == "Fault Handling" else None,
                timeout=300.0  # 5 minutes per question
            )

            if response is None:
                # Timeout - user didn't respond
                await self.viz.send_chat_message(
                    "â±ï¸ Question timeout. Session paused. Resume when ready.",
                    agent_role="SOCRATES"
                )
                return False

            # Process the answer
            if response.lower() == "skip":
                response = "Agent decides"

            self.engine.answer_question(self.current_gap, response)

            status = self.engine.get_status()
            await self.viz.send_chat_message(
                f"âœ“ Got it! [{status['answered']}/{status['total_questions']}]",
                agent_role="SOCRATES"
            )

        # Session complete - show assumptions
        summary = self.engine.get_assumptions_summary()

        final_response = await self.viz.ask_user(
            question=f"âœ… All questions answered!\n\nHere's what I'm assuming:\n{summary}\n\n"
                     f"Is this correct? Anything else I should know?",
            context={"agent_role": "SOCRATES", "stage": "confirmation"},
            options=["Yes, proceed", "No, let me clarify"],
            timeout=300.0
        )

        if final_response and "yes" in final_response.lower():
            await self.viz.send_chat_message(
                "âœ… Specification complete! Generating SPEC nodes for the Architect...",
                agent_role="SOCRATES"
            )
            return True
        else:
            await self.viz.send_chat_message(
                f"ðŸ“ Noted: {final_response}\nPlease provide more details or restart the session.",
                agent_role="SOCRATES"
            )
            return False

    def generate_all_specs(self) -> List[Dict[str, Any]]:
        """Generate SPEC nodes for all features after session completes."""
        specs = []
        for feature in self.engine.parsed.features:
            spec = self.engine.generate_spec_node(feature)
            specs.append(spec)
        return specs


# =============================================================================
# CHAT INTEGRATION HELPERS (CLI fallback)
# =============================================================================

class SocraticChatSession:
    """
    Manages a chat session for Socratic Q&A.

    CLI fallback when VizServer is not available.
    For Mission Control integration, use SocraticVizSession instead.
    """

    def __init__(self, engine: SocraticEngine):
        self.engine = engine
        self.current_gap: Optional[Gap] = None

    def start_session(self, prompt_path: str) -> str:
        """Start a new Socratic session."""
        self.engine.load_prompt(prompt_path)
        self.engine.analyze_gaps()

        status = self.engine.get_status()
        intro = f"""
ðŸ“‹ **Socratic Specification Session**

I've analyzed your requirements and have {status['total_questions']} questions to ensure we build exactly what you need.

Features identified: {status['features_analyzed']}
Questions to answer: {status['remaining']}

Let's begin! You can say "skip" at any time to let me use my best judgment.
"""
        return intro

    def get_next_message(self) -> Optional[str]:
        """Get the next question to ask."""
        self.current_gap = self.engine.get_next_question()

        if not self.current_gap:
            # All questions answered - show assumptions
            summary = self.engine.get_assumptions_summary()
            return f"""
âœ… **All questions answered!**

Here's what I'm assuming:
{summary}

Is this correct? Anything else I should know?

(Type "yes" to proceed, or tell me what to change)
"""

        category_emoji = {
            "Boundary": "ðŸŽ¯",
            "Data Flow": "ðŸ”„",
            "Topology": "ðŸ”—",
            "Data Ownership": "ðŸ“Š",
            "Fault Handling": "âš ï¸",
            "Data Source": "ðŸ“¥",
            "Hidden State": "ðŸ”",
        }.get(self.current_gap.category, "â“")

        return f"""
{category_emoji} **{self.current_gap.category}** ({self.current_gap.question_id})

{self.current_gap.question}

_(Feature: {self.current_gap.feature})_
"""

    def process_answer(self, answer: str) -> str:
        """Process user's answer and return next message."""
        if not self.current_gap:
            return "Session complete! Run the Architect to generate specs."

        if answer.lower() == "skip":
            answer = "Agent decides"

        result = self.engine.answer_question(self.current_gap, answer)

        status = self.engine.get_status()
        progress = f"[{status['answered']}/{status['total_questions']}]"

        if status['remaining'] == 0:
            return self.get_next_message()

        return f"âœ“ Got it! {progress}\n\n" + (self.get_next_message() or "")


# =============================================================================
# CLI ENTRY POINT
# =============================================================================

def main():
    """CLI for Socratic Engine."""
    import argparse

    parser = argparse.ArgumentParser(description="Socratic Specification Engine")
    parser.add_argument("prompt", help="Path to prompt.md file")
    parser.add_argument("--analyze-only", action="store_true", help="Only show gaps, don't start Q&A")
    parser.add_argument("--json", action="store_true", help="Output as JSON")

    args = parser.parse_args()

    engine = SocraticEngine()
    engine.load_prompt(args.prompt)
    gaps = engine.analyze_gaps()

    if args.json:
        output = {
            "status": engine.get_status(),
            "gaps": [
                {
                    "feature": g.feature,
                    "question_id": g.question_id,
                    "question": g.question,
                    "category": g.category,
                    "blocking": g.blocking
                }
                for g in gaps
            ]
        }
        print(json.dumps(output, indent=2))
        return

    if args.analyze_only:
        print(f"\nðŸ“‹ Gap Analysis for: {args.prompt}")
        print(f"   Features: {len(engine.parsed.features)}")
        print(f"   Total gaps: {len(gaps)}")
        print("\nGaps by feature:")
        for gap in gaps:
            print(f"  [{gap.question_id}] {gap.feature}: {gap.category}")
        return

    # Interactive session
    session = SocraticChatSession(engine)
    print(session.start_session(args.prompt))

    while True:
        msg = session.get_next_message()
        if not msg:
            break
        print(msg)

        try:
            answer = input("\n> ").strip()
            if answer.lower() in ["quit", "exit", "q"]:
                break
            response = session.process_answer(answer)
            print(response)
        except KeyboardInterrupt:
            print("\n\nSession cancelled.")
            break

    print("\nâœ… Session complete!")
    print(f"   Answers collected: {len(engine.answers)}")


if __name__ == "__main__":
    main()
